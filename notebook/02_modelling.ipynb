{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Preprocessing](#toc1_)    \n",
    "- [Modelling](#toc2_)    \n",
    "- [Evaluate & Export Model](#toc3_)    \n",
    "- [Metrics](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Data Preprocessing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data.shape: (4000000, 3)\n",
      "raw_data.shape: (400, 3)\n",
      "\n",
      "**View Data Structure**\n",
      "\n",
      "HEAD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Deeply disappointing, faulty morality &amp; social...</td>\n",
       "      <td>The book delves very little into art, aside fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>insight into the philosophy of libertarian soc...</td>\n",
       "      <td>In \"The Limits of State Action\" Enlightenment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>a great book</td>\n",
       "      <td>\"In vain did the Bedouins strive to cut down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>toys for great sex</td>\n",
       "      <td>wow, that was bad, I threw it away after watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>i love this movie!!!!</td>\n",
       "      <td>i just finished reading Someone Like You and i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                       review_title  \\\n",
       "0  __label__1  Deeply disappointing, faulty morality & social...   \n",
       "1  __label__2  insight into the philosophy of libertarian soc...   \n",
       "2  __label__2                                       a great book   \n",
       "3  __label__1                                 toys for great sex   \n",
       "4  __label__2                              i love this movie!!!!   \n",
       "\n",
       "                                                text  \n",
       "0  The book delves very little into art, aside fr...  \n",
       "1  In \"The Limits of State Action\" Enlightenment ...  \n",
       "2  \"In vain did the Bedouins strive to cut down a...  \n",
       "3  wow, that was bad, I threw it away after watch...  \n",
       "4  i just finished reading Someone Like You and i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Trop conervateur</td>\n",
       "      <td>Ce livre nest pas tres petit à vrai dire (asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Classic</td>\n",
       "      <td>This kinda reminds me of the way saves the day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Overpriced</td>\n",
       "      <td>Buyer beware. This pan is not a triply as adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Thoroughly Disappointing</td>\n",
       "      <td>I was anxious to read the sequel to Stargate.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Best film about baseball ever made.</td>\n",
       "      <td>This films documents baseball from 1840 to 200...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         labels                         review_title  \\\n",
       "60   __label__1                     Trop conervateur   \n",
       "210  __label__2                              Classic   \n",
       "88   __label__1                           Overpriced   \n",
       "76   __label__1             Thoroughly Disappointing   \n",
       "49   __label__2  Best film about baseball ever made.   \n",
       "\n",
       "                                                  text  \n",
       "60   Ce livre nest pas tres petit à vrai dire (asse...  \n",
       "210  This kinda reminds me of the way saves the day...  \n",
       "88   Buyer beware. This pan is not a triply as adve...  \n",
       "76   I was anxious to read the sequel to Stargate.....  \n",
       "49   This films documents baseball from 1840 to 200...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>How did this get by me?</td>\n",
       "      <td>Friends of mine and I have been bellyaching ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>BAD TERRIBLE THE WORST SPANISH HORROR MOVIE</td>\n",
       "      <td>This is not scary. It is just plain terrible. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>All I can taste is rancid nuts</td>\n",
       "      <td>No refined sugar, no gluten, dairy or soy, no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Motive Product Power Bleeder Review</td>\n",
       "      <td>The instructions were good. Very easy to use a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Truly A Caldecott Classic</td>\n",
       "      <td>Owl Moon by Jane Yolen in my opinion is one of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         labels                                 review_title  \\\n",
       "395  __label__2                      How did this get by me?   \n",
       "396  __label__1  BAD TERRIBLE THE WORST SPANISH HORROR MOVIE   \n",
       "397  __label__1               All I can taste is rancid nuts   \n",
       "398  __label__2          Motive Product Power Bleeder Review   \n",
       "399  __label__2                    Truly A Caldecott Classic   \n",
       "\n",
       "                                                  text  \n",
       "395  Friends of mine and I have been bellyaching ab...  \n",
       "396  This is not scary. It is just plain terrible. ...  \n",
       "397  No refined sugar, no gluten, dairy or soy, no ...  \n",
       "398  The instructions were good. Very easy to use a...  \n",
       "399  Owl Moon by Jane Yolen in my opinion is one of...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Info Summary**\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   labels        400 non-null    object\n",
      " 1   review_title  397 non-null    object\n",
      " 2   text          400 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 250.3 KB\n",
      "\n",
      "**Summary Statistics**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400</td>\n",
       "      <td>397</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>393</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>The book delves very little into art, aside fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>213</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            labels  review_title  \\\n",
       "count          400           397   \n",
       "unique           2           393   \n",
       "top     __label__2  Disappointed   \n",
       "freq           213             3   \n",
       "\n",
       "                                                     text  \n",
       "count                                                 400  \n",
       "unique                                                400  \n",
       "top     The book delves very little into art, aside fr...  \n",
       "freq                                                    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Handle Missing Values**\n",
      "\n",
      "review_title    3\n",
      "labels          0\n",
      "text            0\n",
      "dtype: int64\n",
      "\n",
      "Actual Missing Values\n",
      "\n",
      "labels          0\n",
      "review_title    0\n",
      "text            0\n",
      "dtype: int64\n",
      "\n",
      "**Remove Duplicates**\n",
      "\n",
      "There are no duplicated values.\n",
      "ACTUAL SHAPE: (400, 3)\n",
      "\n",
      "**Translate Text**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Text: 100%|██████████| 400/400 [00:00<00:00, 426.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Handle Outliers**\n",
      "\n",
      "Number of detected outliers: 0\n",
      "SHAPE BEFORE: (400, 4)\n",
      "ACTUAL SHAPE: (400, 4)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 12:43:35.635668: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-18 12:43:35.647924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-18 12:43:35.665096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-18 12:43:35.665166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-18 12:43:35.675877: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 12:43:36.673942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LABELS:\n",
      "1.0\n",
      "\n",
      "X_train shape: (320, 50)\n",
      "X_test shape: (80, 50)\n",
      "y_train shape: (320,)\n",
      "y_test shape: (80,)\n"
     ]
    }
   ],
   "source": [
    "# Constants & Hyperparameters to define\n",
    "VERBOSE = True\n",
    "RANDOM_SEED = 42\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORDS = 5000\n",
    "MAX_SEQ_LEN = 50\n",
    "EMBEDDING_DIM = 50\n",
    "NUM_FILTERS = 64\n",
    "KERNEL_SIZE = 5\n",
    "NUM_CLASSES = 2\n",
    "SAMPLE_FRAC = 0.0001\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import Functions\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import DataInspection, HandleMissingValues, RemoveDuplicates, TranslateText, HandleOutliers, SplitDataset\n",
    "\n",
    "# Initialize Preprocessing Steps\n",
    "data_inspection = DataInspection()\n",
    "handle_missing_values = HandleMissingValues()\n",
    "remove_duplicates = RemoveDuplicates()\n",
    "translate_text = TranslateText()\n",
    "handle_outliers = HandleOutliers()\n",
    "split_dataset = SplitDataset()\n",
    "\n",
    "\n",
    "data_inspection.set_next(handle_missing_values)\n",
    "handle_missing_values.set_next(remove_duplicates)\n",
    "remove_duplicates.set_next(translate_text)\n",
    "translate_text.set_next(handle_outliers)\n",
    "handle_outliers.set_next(split_dataset)\n",
    "\n",
    "# Chain Preprocessing Steps\n",
    "data_inspection.set_next(handle_missing_values)\n",
    "handle_missing_values.set_next(remove_duplicates)\n",
    "remove_duplicates.set_next(translate_text)\n",
    "translate_text.set_next(handle_outliers)\n",
    "handle_outliers.set_next(split_dataset)\n",
    "\n",
    "# Load Data\n",
    "raw_data = pd.read_csv('../data/raw_data.csv')\n",
    "print(f'raw_data.shape: {raw_data.shape}')\n",
    "\n",
    "######################################################################\n",
    "# Sample the data\n",
    "raw_data = raw_data.sample(frac=SAMPLE_FRAC, \n",
    "    random_state=RANDOM_SEED, \n",
    "    ignore_index=True)\n",
    "\n",
    "print(f'raw_data.shape: {raw_data.shape}')\n",
    "######################################################################\n",
    "\n",
    "# Execute the pipeline\n",
    "X_train, X_test, y_train, y_test = data_inspection.process(raw_data, VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Modelling](#toc0_)\n",
    "\n",
    "**Sequential convolutional neural network (CNN) for text classification**\n",
    "\n",
    "1. Embedding Layer\n",
    "* `Embedding(input_dim=5000, output_dim=100, input_length=100)`\n",
    "* `input_dim=5000`: This specifies the vocabulary size, meaning the model can handle up to **5000** unique words.\n",
    "* `output_dim=100`: This defines the dimensionality of the embedding vector, which compresses each word into a **100**-dimensional vector.\n",
    "* `input_length=100`: This sets the maximum length of the input text sequences (sentences or paragraphs) to **100** words.\n",
    "\n",
    "2. Convolutional Layer\n",
    "* `Conv1D(filters=64, kernel_size=5, activation='relu')`: This 1D convolutional layer extracts features from the embedded text sequences.\n",
    "* `filters=64`: This indicates the number of filters used to identify patterns in the text.\n",
    "* `kernel_size=5`: This defines the size of the window that the filter slides over the text sequence (**5** words in this case).\n",
    "* `activation='relu'`: This activation function introduces non-linearity, allowing the model to learn complex relationships between words.\n",
    "\n",
    "    * `'relu'` means Rectified Linear Unit (ReLU). \n",
    "    * For any input value $(x)$, it outputs the value itself if it's positive $(x > 0)$ and zero otherwise $(x <= 0)$. \n",
    "    * Mathematically, it can be represented as:\n",
    "    * $f(x) = max(0, x)$\n",
    "\n",
    "3. Pooling Layer\n",
    "* `MaxPooling1D(pool_size=4)`: This layer reduces the dimensionality of the data by taking the maximum value from every window of size **4** along the sequence This helps control overfitting and focuses on the most important features.\n",
    "\n",
    "4. Flattening Layer\n",
    "* `Flatten()`: This layer transforms the 2D output from the convolutional layer into a 1D vector suitable for feeding into the fully connected layers.\n",
    "\n",
    "5. Fully Connected Layers\n",
    "* `Dense(10, activation='relu')`: This first fully connected layer has **10** neurons and uses the ReLU activation function. It learns higher-level features by combining the extracted features from the convolutional layers.\n",
    "\n",
    "* `Dense(3, activation='softmax')`: This final fully connected layer has 3 neurons and uses the softmax activation function. It outputs a probability distribution over 3 categories, making it suitable for multi-class classification tasks (e.g., classifying text into 3 different genres).\n",
    "\n",
    "    * `'softmax'`: For each element $(i)$ in the input vector, softmax calculates the probability $(p_i)$ using the following formula:\n",
    "    * $p_i = exp(x_i) / Σ(exp(x_j))$  for all $j$ in the vector\n",
    "    * Here, $exp(x_i)$ represents the exponentiation of the i-th element in the input vector.\n",
    "    * $Σ(exp(x_j))$ represents the sum of the exponentials of all elements in the vector.\n",
    "\n",
    "6. Compiling the Model:\n",
    "* `model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])`: This compiles the model by specifying the optimizer (Adaptive Moment Estimation (Adam) for efficient training), the loss function (sparse categorical crossentropy for multi-class classification), and the metrics (accuracy to measure performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<dtype: 'float32'>\n",
      "tf.Tensor(\n",
      "[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.  797.   13.   14.  104.\n",
      "    4. 2401.    7.  291.   81.  396.    7.  336. 2402.  150. 1484.    8.\n",
      "    7.  255.    5.  114.  151. 1485.    7.  141.  565.  241. 1050. 1479.\n",
      "   67.  205.], shape=(50,), dtype=float32)\n",
      "\n",
      "\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<dtype: 'float32'>\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 12:43:37.299974: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-18 12:43:37.300022: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: heroines\n",
      "2024-07-18 12:43:37.300028: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: heroines\n",
      "2024-07-18 12:43:37.300253: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 550.90.7\n",
      "2024-07-18 12:43:37.300280: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 550.90.7\n",
      "2024-07-18 12:43:37.300283: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 550.90.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4693 - loss: 0.6954 - precision: 0.4600 - recall: 0.7514 - val_accuracy: 0.5156 - val_loss: 0.6921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6884 - loss: 0.6816 - precision: 1.0000 - recall: 0.2993 - val_accuracy: 0.5781 - val_loss: 0.6902 - val_precision: 0.6250 - val_recall: 0.3226\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9034 - loss: 0.6541 - precision: 0.9729 - recall: 0.8257 - val_accuracy: 0.5781 - val_loss: 0.6889 - val_precision: 0.5667 - val_recall: 0.5484\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.6193 - precision: 1.0000 - recall: 0.8955 - val_accuracy: 0.5000 - val_loss: 0.6873 - val_precision: 0.4286 - val_recall: 0.0968\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9227 - loss: 0.5744 - precision: 1.0000 - recall: 0.8328 - val_accuracy: 0.5312 - val_loss: 0.6845 - val_precision: 0.6000 - val_recall: 0.0968\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.5107 - precision: 1.0000 - recall: 0.9293 - val_accuracy: 0.5469 - val_loss: 0.6799 - val_precision: 0.5238 - val_recall: 0.7097\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.4067 - precision: 1.0000 - recall: 0.9845 - val_accuracy: 0.6094 - val_loss: 0.6696 - val_precision: 0.6667 - val_recall: 0.3871\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.3063 - precision: 1.0000 - recall: 0.9720 - val_accuracy: 0.6406 - val_loss: 0.6543 - val_precision: 0.6000 - val_recall: 0.7742\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1983 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.6719 - val_loss: 0.6363 - val_precision: 0.6562 - val_recall: 0.6774\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1103 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.7031 - val_loss: 0.6185 - val_precision: 0.6875 - val_recall: 0.7097\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import visualkeras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# Disable XLA JIT Compilation\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "padded_sequences = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "labels = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "\n",
    "print('\\n')\n",
    "print(type(padded_sequences))\n",
    "print(padded_sequences.dtype)\n",
    "print(padded_sequences[0])\n",
    "print('\\n')\n",
    "print(type(labels))\n",
    "print(labels.dtype)\n",
    "print(labels[0])\n",
    "print('\\n')\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=NUM_WORDS, \n",
    "        output_dim=EMBEDDING_DIM, \n",
    "        input_length=MAX_SEQ_LEN),\n",
    "    Conv1D(\n",
    "        filters=NUM_FILTERS, \n",
    "        kernel_size=KERNEL_SIZE, \n",
    "        activation='relu', \n",
    "        padding='same'),\n",
    "    MaxPooling1D(\n",
    "        pool_size=4, \n",
    "        padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(\n",
    "        10, \n",
    "        activation='relu'),\n",
    "    Dense(\n",
    "        1, \n",
    "        activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "# Fit the model    \n",
    "model.fit(x=padded_sequences, \n",
    "    y=labels, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2)\n",
    "\n",
    "# Visualize the CNN scheme\n",
    "visualkeras.layered_view(\n",
    "    model, \n",
    "    legend=True, \n",
    "    draw_volume=True, \n",
    "    scale_xy=2, \n",
    "    scale_z=2, \n",
    "    max_z=1000,\n",
    "    to_file='output.png'\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Evaluate & Export Model](#toc0_)\n",
    "\n",
    "$F1-score=2×(Precision+Recall)/(Precision×Recall)​$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6359 - loss: 0.6458 - precision: 0.5541 - recall: 0.6160  \n",
      "Accuracy:\t 0.6000\n",
      "Precision:\t 0.5278\n",
      "Recall:\t\t 0.5588\n",
      "F1-score:\t 0.5429\n",
      "INFO:tensorflow:Assets written to: ../model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138950431087248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138950431218320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138950430842544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138950430895264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138950430956880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138950430497424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138950430554768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy, model_precision, model_recall = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Calculate the F1-score\n",
    "if (model_precision + model_recall) == 0:\n",
    "    model_f1_score = 0\n",
    "else:\n",
    "    model_f1_score = 2 * (model_precision * model_recall) / (model_precision + model_recall)\n",
    "\n",
    "print(f'Accuracy:\\t {model_accuracy:.4f}')\n",
    "print(f'Precision:\\t {model_precision:.4f}')\n",
    "print(f'Recall:\\t\\t {model_recall:.4f}')\n",
    "print(f'F1-score:\\t {model_f1_score:.4f}')\n",
    "\n",
    "# Export model\n",
    "model.export('../model')\n",
    "\n",
    "'''\n",
    "# Later, in a different process / environment...\n",
    "reloaded_artifact = tf.saved_model.load(\"path/to/location\")\n",
    "predictions = reloaded_artifact.serve(input_data)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Metrics](#toc0_)\n",
    "\n",
    "**Sample 0.0001**:\n",
    "\n",
    "$0.5750$ - Accuracy         \n",
    "$0.5000$ - Precision        \n",
    "$0.1176$ - Recall       \n",
    "$0.1905$ - F1-score     \n",
    "\n",
    "**Sample 0.001**:\n",
    "      \n",
    "$0.5938$ - Accuracy     \n",
    "$0.5610$ - Precision        \n",
    "$0.5806$ - Recall     \n",
    "$0.5707$ - F1-score\n",
    "\n",
    "**Sample 0.01**:\n",
    "\n",
    "$0.6658$ - Accuracy         \n",
    "$0.6552$ - Precision        \n",
    "$0.6726$ - Recall       \n",
    "$0.6638$ - F1-score     \n",
    "\n",
    "**Sample 0.1**:\n",
    "\n",
    "$0.7249$ - Accuracy         \n",
    "$0.7284$ - Precision        \n",
    "$0.7161$ - Recall       \n",
    "$0.7222$ - F1-score    \n",
    "\n",
    "**Sample 0.2**:\n",
    "\n",
    "$0.7377$ - Accuracy         \n",
    "$0.7338$ - Precision        \n",
    "$0.7451$ - Recall       \n",
    "$0.7394$ - F1-score  \n",
    "\n",
    "**Sample 0.5**:\n",
    "\n",
    "$0.7438$ - Accuracy         \n",
    "$0.7481$ - Precision        \n",
    "$0.7349$ - Recall       \n",
    "$0.7415$ - F1-score  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
